3.29*****************

Twin networks:matching the future for ....
主要提出了一个双向的rnn网络,这个网络的节点可以是lstm或者gru,它主要是为了regularizes the hidden states.他的到灵感的地方是:a.backward hidden states contain a summary of the future of the sequence b.in order to predict the future more accurately,the model will have to form a better representation of the past
另外,这个模型使用的neuraltalk2的代码,可以借来使用,这个代码是由pytorch写的.

3.31*****************

#Plan,Attend,Generate:Planning for sequence....
一个叫做plan的机制,通过使用Alignment metrix 和commitment plan vector,解决sequence to sequence问题
论文附有代码地址,由theano 框架编写.

#MAt:a multimodal attentive translator for image caption
核心创新点是:不使用图像的feature(cnn)作为输入,而是使用detected objects作为输入,从而达到了sequence to sequence的效果.并且使用了基于sequence 的attention机制.
他的attention机制的特点是使用encoding阶段的hidden states作为y1,y2,y3...而decoding hidden state 作为C.yn和C作为输入,输出Z.
他的object detector 使用的是R-FCN[Jifeng et al.,2016],最后的结果总体较好,cider得分为1.029,b4得分为0.320

4.1******************

#From Caption to visual concepts and back
核心要点是先检测图片中的词语,然后合成句子,最后选择句子中最好的一个,关键在于检测词语的阶段,他是直接使用caption来训练的.
使用这个方法的出发点是因为1:caption中蕴含更具有显著性的信息2:caption中能获得更有常识性的知识.3:能更好评测句子和图片的相似性,从而获取更匹配的caption.

#Improved Image Captioning via Policy.....
SPICE主要关注semantic,CIDEr主要关注syntactic,所以这篇文章结合了两者,得到一个新的metric:SPIDEr,从而可以兼顾.另外,这篇文章提到scheduled sampling具有statistically问题.
文章使用了polly gradient方法结合MC rollouts,并且使用cnn-rnn预训练了模型.PG training 要比 MLE training 快很多.
这个论文说明了各个metric之间的线性组合可以得到比较好的结果.
另外,这篇论文提到一个问题,就是metric分值高并不一定说明更好的caption,可以使用人工测评.

4.2*******************

#SCA-CNN:Spatial and Channel-wise attention in ......
这篇论文主要提出了一个复合的attention机制,首先从CNN中提取不同的层(其中low level layer主要检测像edge,corner这样的特征,而high level layer主要检测像parts和object这样的特征),其中每层中又有channel-wise attention 和spatial attention,这两个attention结合起来共同作用.
人眼识别图像并不是一瞬间就看到图像的全部,而是注意到某些区域,因此,attention机制得以成功.
另外,这篇文章最后通过提问,然后一一解答的方式来展开篇幅,这个可以借鉴过来.
最后,github上面有代码,搜索sca-cnn.

#Stack-Captioning:coarse-to-fine learning for image captioning
使用了堆叠的decoder,从而得到refined caption of image,另外,这篇文章使用了PG方法.
文章中多个decoder堆叠方法值得一看,另外文章提供了代码.
训练deep network 时候,容易出现gradient vanishing problem,所以这篇文章使用了rl方法,而不是XE方法.

4.8******************
#Bottom-Up and Top-Down Attention for Image Caption.....
这篇论文的要点在于,他使用的feature是首先用faster r-cnn检测到的object,比起直接平等分得到的feature要好的多,另外,它使用了两层lstm,一层top_down,上面是language lstm,两层中间是attend.第一层的输入是average feature,h2t,and word,输出ht,然后....(看图就行了)


