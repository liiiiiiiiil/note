3.29*****************

Twin networks:matching the future for ....
主要提出了一个双向的rnn网络,这个网络的节点可以是lstm或者gru,它主要是为了regularizes the hidden states.他的到灵感的地方是:a.backward hidden states contain a summary of the future of the sequence b.in order to predict the future more accurately,the model will have to form a better representation of the past
另外,这个模型使用的neuraltalk2的代码,可以借来使用,这个代码是由pytorch写的.

3.31*****************

Plan,Attend,Generate:Planning for sequence....
一个叫做plan的机制,通过使用Alignment metrix 和commitment plan vector,解决sequence to sequence问题
论文附有代码地址,由theano 框架编写.

MAt:a multimodal attentive translator for image caption
核心创新点是:不使用图像的feature(cnn)作为输入,而是使用detected objects作为输入,从而达到了sequence to sequence的效果.并且使用了基于sequence 的attention机制.
他的attention机制的特点是使用encoding阶段的hidden states作为y1,y2,y3...而decoding hidden state 作为C.yn和C作为输入,输出Z.
他的object detector 使用的是R-FCN[Jifeng et al.,2016],最后的结果总体较好,cider得分为1.029,b4得分为0.320


