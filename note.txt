3.29*****************

Twin networks:matching the future for ....
主要提出了一个双向的rnn网络,这个网络的节点可以是lstm或者gru,它主要是为了regularizes the hidden states.他的到灵感的地方是:a.backward hidden states contain a summary of the future of the sequence b.in order to predict the future more accurately,the model will have to form a better representation of the past
另外,这个模型使用的neuraltalk2的代码,可以借来使用,这个代码是由pytorch写的.

3.31*****************

#Plan,Attend,Generate:Planning for sequence....
一个叫做plan的机制,通过使用Alignment metrix 和commitment plan vector,解决sequence to sequence问题
论文附有代码地址,由theano 框架编写.

#MAt:a multimodal attentive translator for image caption
核心创新点是:不使用图像的feature(cnn)作为输入,而是使用detected objects作为输入,从而达到了sequence to sequence的效果.并且使用了基于sequence 的attention机制.
他的attention机制的特点是使用encoding阶段的hidden states作为y1,y2,y3...而decoding hidden state 作为C.yn和C作为输入,输出Z.
他的object detector 使用的是R-FCN[Jifeng et al.,2016],最后的结果总体较好,cider得分为1.029,b4得分为0.320

4.1******************

#From Caption to visual concepts and back
核心要点是先检测图片中的词语,然后合成句子,最后选择句子中最好的一个,关键在于检测词语的阶段,他是直接使用caption来训练的.
使用这个方法的出发点是因为1:caption中蕴含更具有显著性的信息2:caption中能获得更有常识性的知识.3:能更好评测句子和图片的相似性,从而获取更匹配的caption.

#Improved Image Captioning via Policy.....
SPICE主要关注semantic,CIDEr主要关注syntactic,所以这篇文章结合了两者,得到一个新的metric:SPIDEr,从而可以兼顾.另外,这篇文章提到scheduled sampling具有statistically问题.
文章使用了polly gradient方法结合MC rollouts,并且使用cnn-rnn预训练了模型.PG training 要比 MLE training 快很多.
这个论文说明了各个metric之间的线性组合可以得到比较好的结果.
另外,这篇论文提到一个问题,就是metric分值高并不一定说明更好的caption,可以使用人工测评.

4.2*******************

#SCA-CNN:Spatial and Channel-wise attention in ......
这篇论文主要提出了一个复合的attention机制,首先从CNN中提取不同的层(其中low level layer主要检测像edge,corner这样的特征,而high level layer主要检测像parts和object这样的特征),其中每层中又有channel-wise attention 和spatial attention,这两个attention结合起来共同作用.
人眼识别图像并不是一瞬间就看到图像的全部,而是注意到某些区域,因此,attention机制得以成功.
另外,这篇文章最后通过提问,然后一一解答的方式来展开篇幅,这个可以借鉴过来.
最后,github上面有代码,搜索sca-cnn.

#Stack-Captioning:coarse-to-fine learning for image captioning
使用了堆叠的decoder,从而得到refined caption of image,另外,这篇文章使用了PG方法.
文章中多个decoder堆叠方法值得一看,另外文章提供了代码.
训练deep network 时候,容易出现gradient vanishing problem,所以这篇文章使用了rl方法,而不是XE方法.

4.8******************
#Bottom-Up and Top-Down Attention for Image Caption.....
这篇论文的要点在于,他使用的feature是首先用faster r-cnn检测到的object,比起直接平等分得到的feature要好的多,另外,它使用了两层lstm,一层top_down,上面是language lstm,两层中间是attend.第一层的输入是average feature,h2t,and word,输出ht,然后....(看图就行了)


4.13*****************
实验了topdown模型,发现以下问题:1.容易出现误判   2.这个问题比较严重,比如:a clock is on a wall with a clock,这个问题可能是lstm自身的问题,之前的clock 被遗忘了,然后产生新的clock.事实上,a clock is on a wall,和a wall with a clock 都是符合语法语义的句子.  3.忽略性,比如一个盘子装了一块牛排,他直接得到 a plate with food,而忽略了牛排,可能是因为牛排并没有出现过几次把.

4.14****************
#From captions to visual oncepts and back(the second times)
这篇论文使用的detecte word 的方法是一个叫做MIL(multiple instance learning)的方法,首先,caption中所用到的词语是有限的,所以1000个词语就占据了90%多....MIL模型我没看懂,也不想看.他可以不用产生bounding boxes 但是也能detect words.

#我突然发现,目前的image caption算法,已经取得非常好的效果了,不好的地方,也只是个别物体检测错误,还有复杂环境下生成caption,另外,还有生成的句子比较简单.  所以这一次尝试过后,如果还没有成果,那么就赶紧放弃,开始做video,这一块的意义更大,虽然各方面难度比较大,但是一定能够克服!


5.7***************
#Entity-aware image caption generation
这篇文章首先通过自己收集的数据,这个数据的caption是template的caption,然后通过tag,结合知识图谱,最后把这些词语填入到template中,可以生成更加细致的caption,比如这样的caption可以包含人名,地名,时间等等.

#Improved image captioning with adversarial semantic alignment
这篇文章使用的gan和scst的方法,但主要贡献是它生成的caption具有:sematic alignment between image and caption.
另外,他的 co-attention discriminator 的结构很有意思,可以一看.
最后,gan结合scst是目前相对来说效果最好的方法了,所以如果要有自己的idea,就得结合这种训练方法.

#object counts!bringing explicit detetions back into image captioning
这篇文章主要介绍object detection 的重要性,它分别测试了 frequency,distance,size等属性对与结果的影响,可以作为以后的参考,但是最主要的是我们需要记住detection的重要性.

5.10**************
#Learning to guide decoding for image captioning
image caption 的一个问题就是在训练时候的decode过程,产生句子的时候,每个句子的产生是同事需要以来caption 还有 image的,但是在这种情况下很难保持他们的平衡,从而导致某个元素影响过于大的情况,我之前想法是可以使用object detection 去critic ,但是这里给了我一个思路,从新构造一个guide network,去guide整个decode过程.这个guide network 是一个神经网络,但是细节可以随时来查.


